<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Obtaining Uncertainty Estimates from Neural Networks Using TensorFlow Probability</title>
    <meta charset="utf-8" />
    <meta name="author" content="Sigrid Keydana" />
    <link rel="stylesheet" href="theme/rstudio.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Obtaining Uncertainty Estimates from Neural Networks Using TensorFlow Probability
### Sigrid Keydana
### Predictive Analytics World 2019

---


class: inverse, middle, center

# Neural networks are awesome ...


---

# Deep learning yields excellent results in e.g. 

&lt;br /&gt;

- Image recognition (classification, segmentation, object detection)

- Natural language processing (language models, translation, generation)

- Domain modeling (embeddings)

- Entity generation ("fakes"): Faces, text ...

- Tasks involving tabular data (e.g., recommender systems)

- Playing games (deep reinforcement learning)

---

class: inverse, middle, center

# So what are we missing?

---

# Networks output _point estimates_

&lt;br /&gt;


- A single numeric prediction 

- A single segmentation mask

- A single translation

- A single embedding

&lt;br /&gt;
 
But wait ... aren't there probabilities in there, _somewhere_?

---
# Name that animal

&lt;figure&gt;
&lt;img src="https://raw.githubusercontent.com/skeydan/whyR2019/master/p1.png"/&gt;
&lt;figcaption&gt;&lt;br /&gt;Image: Ben Tubby [CC BY 2.0 (https://creativecommons.org/licenses/by/2.0)]
https://upload.wikimedia.org/wikipedia/commons/3/30/Falkland_Islands_Penguins_35.jpg&lt;/figcaption&gt;
&lt;/figure&gt;

Let's ask the network ...


---
# What network?

... TensorFlow, but from R!

&lt;figure&gt;
    &lt;img src="dlwr.jpg" style = "float:left;" width= "35%"&gt;
&lt;/figure&gt;
&lt;figure&gt;
    &lt;img src="r-tf.png" style = "float:right;" width= "45%"&gt;
&lt;/figure&gt;


---
# R-TensorFlow

&lt;br /&gt; 
- [R bindings to TensorFlow](https://tensorflow.rstudio.com/) (subsumes Keras)

- TensorFlow-related infrastructure...
  - [Dataset preprocessing pipeline](https://github.com/rstudio/tfdatasets)
  - [TensorFlow datasets](https://github.com/rstudio/tfds)
  - [tfhub](https://github.com/rstudio/tfhub)
  - and more ...

- [_r-tensorflow_ ecosystem](https://github.com/r-tensorflow):
  - Model implementations, e.g. U-Net, WaveNet ... 
  - User-contributed packages for automation, tuning, ...

- Blog: https://blogs.rstudio.com/tensorflow/

---
# With R-Keras, let's ask a pretrained model...


```r
library(tensorflow)
library(keras)

model &lt;- application_mobilenet_v2()
probs &lt;- model %&gt;% predict(image)
imagenet_decode_predictions(probs)
```

&lt;br /&gt;

```
  class_name class_description        score
1  n02056570      king_penguin 0.9899597168
2  n01847000             drake 0.0011793933
3  n01798484   prairie_chicken 0.0002387235
4  n02058221         albatross 0.0002117234
5  n02071294      killer_whale 0.0001432021
```

---
# Let's do another one

&lt;figure&gt;
&lt;img src="https://raw.githubusercontent.com/skeydan/whyR2019/master/p2.png"/&gt;
&lt;figcaption&gt;&lt;br /&gt;Image: M. Murphy [Public domain]&lt;br /&gt;
https://upload.wikimedia.org/wikipedia/commons/2/22/RoyalPenguins3.JPG&lt;/figcaption&gt;
&lt;/figure&gt;


---
# So what is that?


```r
probs &lt;- model %&gt;% predict(image)
imagenet_decode_predictions(probs)
```

&lt;br /&gt;

```
  class_name class_description      score
1  n02051845           pelican 0.24614049
2  n02009912    American_egret 0.18564136
3  n02058221         albatross 0.06848499
4  n02012849             crane 0.04572001
5  n02009229 little_blue_heron 0.03902744
```
&lt;br /&gt;

### Hm... what really is that _score_?

---
# Stepping back: What's a neural network?


&lt;img src="https://raw.githubusercontent.com/skeydan/whyR2019/master/playground.png" width = "70%"/&gt;

---
# Zooming in: Weights and activations

&lt;figure&gt;
    &lt;img src="https://raw.githubusercontent.com/skeydan/whyR2019/master/perceptron.png" width = "60%"&gt;
    &lt;figcaption&gt;Source: https://en.wikipedia.org/wiki/Perceptron&lt;/figcaption&gt;
&lt;/figure&gt;


---

# Activation functions in regression


```r
model &lt;- keras_model_sequential() %&gt;%
  layer_dense(units = 32, activation = "relu", input_shape = 7) %&gt;%
  # default activation = linear
  layer_dense(units = 1)
```

&lt;figure&gt;
    &lt;img src="https://raw.githubusercontent.com/skeydan/whyR2019/master/relu.png" width = "60%"&gt;
    &lt;figcaption&gt;&lt;b&gt;ReLU&lt;/b&gt; activation&lt;/figcaption&gt;
&lt;/figure&gt;


---

# Sigmoid activation for binary classification


```r
model &lt;- keras_model_sequential() %&gt;%
  layer_dense(units = 32, activation = "relu", input_shape = 7) %&gt;%
  layer_dense(units = 1, activation = "sigmoid")
```

&lt;figure&gt;
    &lt;img src="https://raw.githubusercontent.com/skeydan/whyR2019/master/sigmoid.png" width = "60%"&gt;
    &lt;figcaption&gt;&lt;b&gt;Sigmoid&lt;/b&gt; activation&lt;/figcaption&gt;
&lt;/figure&gt;

---

# Softmax activation for multiple classification


```r
model &lt;- keras_model_sequential() %&gt;%
  layer_dense(units = 32, activation = "relu", input_shape = 7) %&gt;%
  layer_dense(units = 10, activation = "softmax")
```

&lt;br /&gt;

&lt;figure&gt;
    &lt;img src="https://raw.githubusercontent.com/skeydan/whyR2019/master/softmax_pre.png" style = "float:left;" width= "50%"&gt;
&lt;/figure&gt;
&lt;figure&gt;
    &lt;img src="https://raw.githubusercontent.com/skeydan/whyR2019/master/softmax_post.png" style = "float:right;" width= "50%"&gt;
&lt;/figure&gt;

Before and after __softmax__ activation.

---

# So our "probability" is just a maximum likelihood estimate ...

&lt;br /&gt;

... how can we make this probabilistic?

---
class: inverse, middle, center

# Indirect ways: ensembling (model averaging), dropout ...


---
# Dropout uncertainty (Gal &amp; Ghahramani, 2016) &lt;sup&gt;1&lt;/sup&gt;

&lt;br /&gt;

- _dropout_: stochastic removal of units in hidden (or input) layers

- habitually used as a regularization measure during training

- idea: use at test time and average predictions

&lt;br /&gt;

## Question: How to choose the dropout rate?


.footnote[
[1] Gal and Ghahramani (2016): Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning
]





---
# Dropout uncertainty, next level (Kendall &amp; Gal, 2017) &lt;sup&gt;1&lt;/sup&gt;&lt;sup&gt;2&lt;/sup&gt;

&lt;br /&gt; 

- let the network learn the dropout rate

- let the network learn the variance (account for _heteroscedasticity_)

- independently calculate _epistemic_ and _aleatoric_ uncertainty

.footnote[
[1] Kendall &amp; Gal (2017): What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?

[2] Gal, Hron, &amp; Kendall (2017): Concrete Dropout.
]

---
# Types of uncertainty: aleatoric vs. epistemic&lt;sup&gt;1&lt;/sup&gt;

- aleatoric: 

  - variation due to measurement process, irreducible
  
  - "known unknowns"
  
- epistemic:

  - insufficiency in the model; reducible by getting more data
  
  - "unknown unknowns"


.footnote[
[1]
Hora, S. (1996) Aleatory and epistemic uncertainty in probability elicitation with an example from hazardous waste management.
]


---
# Yet more terminology? How does this matter?

&lt;br /&gt;

- Circle in what you don't know ...

  - get more data
  - try other models / model families
  - try getting more context
  
  
- Deal with unavoidable risk (safety margins)

  - include complementary methods
  - keep in mind in subsequent decision-making 

---
# Assessing both types of uncertainty, the Gal et al. way

&lt;br /&gt;

- __Aleatoric__: Have network output not just predictive mean, but also _predictive variance_

- Learning different variances for different data points!

- __Epistemic__: Use Monte Carlo sampling to calculate variance of predictions (that are inherently probabilistic due to use of dropout at test time) 

- Making use of learned dropout rate



---
class: inverse, middle, center

## This is nice, but computationally intensive, and, well, _indirect_ ...


---
class: inverse, middle, center

# Enter the direct way: Bayesian networks!

---

# The idea: Put distributions over the network's weights


&lt;figure&gt;
    &lt;img src="https://raw.githubusercontent.com/skeydan/whyR2019/master/weight_uncertainty.png" width = "120%"&gt;
    &lt;figcaption&gt;Blundell et al. (2015): Weight Uncertainty in Neural Networks&lt;/figcaption&gt;
&lt;/figure&gt;


---
# The idea itself is all but new...

&lt;br /&gt;

- McKay (1992): A practical Bayesian framework for backprop networks
- Hinton and van Camp (1993): Keeping neural networks simple by minimizing the description length of the weights
- R. Neal (1996): Bayesian learning for neural networks

&lt;br /&gt;

## ... but gained momentum rather recently:

- Graves (2011): Practical Variational Inference for Neural Networks
- Kingma et al. (2015): Variational dropout and the local reparameterization trick
- Blundell et al. (2015): Weight uncertainty in neural networks 

---
# So how can we do this?

&lt;br /&gt;

[TensorFlow Probability](https://www.tensorflow.org/probability/) (Python library on top of TensorFlow)

[tfprobability](https://rstudio.github.io/tfprobability/) (R package)

&lt;br /&gt;


```r
install.packages("tfprobability")

library(tfprobability)
install_tfprobability()
```


---
# tfprobability (1): Basic building blocks

#### Distributions


```r
d &lt;- tfd_binomial(total_count = 7, probs = 0.3)
d %&gt;% tfd_mean()
#&gt; tf.Tensor(2.1000001, shape=(), dtype=float32)
d %&gt;% tfd_variance()
#&gt; tf.Tensor(1.47, shape=(), dtype=float32)
d %&gt;% tfd_log_prob(2.3)
#&gt; tf.Tensor(-1.1914139, shape=(), dtype=float32)
```

#### Bijectors


```r
b &lt;- tfb_affine_scalar(shift = 3.33, scale = 0.5)
x &lt;- c(100, 1000, 10000)
b %&gt;% tfb_forward(x)
#&gt; tf.Tensor([  53.33  503.33 5003.33], shape=(3,), dtype=float32)
```



---
# tfprobability (2): Higher-level modules

&lt;br /&gt;

- Keras layers 

- Markov Chain Monte Carlo (Hamiltonian Monte Carlo, NUTS)

- Variational inference

- State space models

- GLMs

---
class: inverse, middle, center

# How does that help us?


---
# With TFP, neural network layers can be _distributions_

&lt;br /&gt;
A network that has a multivariate normal distribution as output


```r
model &lt;- keras_model_sequential() %&gt;%
  layer_dense(units = params_size_multivariate_normal_tri_l(d)) %&gt;%
  layer_multivariate_normal_tri_l(event_size = d)

log_loss &lt;- function (y, model) - (model %&gt;% tfd_log_prob(y))

model %&gt;% compile(optimizer = "adam", loss = log_loss)

model %&gt;% fit(
  x,
  y,
  batch_size = 100,
  epochs = 1,
  steps_per_epoch = 10
)
```


---
# Back to uncertainty...

&lt;br /&gt;

- If our network can output a distribution, we can have it learn the distribution's parameters

- Choosing e.g. a normal distribution, we can train the network to learn the actual _spread_ in the data

- Thus, we have found a way to estimate _aleatoric_ uncertainty



---
# Example: Aleatoric uncertainty 




```r
model &lt;- keras_model_sequential() %&gt;%
  layer_dense(units = 8, activation = "relu") %&gt;%
  layer_dense(units = 2, activation = "linear") %&gt;%
  layer_distribution_lambda(function(x)
    tfd_normal(loc = x[, 1, drop = FALSE],
               scale = 1e-3 + tf$math$softplus(x[, 2, drop = FALSE])
               )
  )

negloglik &lt;- function(y, model) - (model %&gt;% tfd_log_prob(y))

model %&gt;% compile(
  optimizer = optimizer_adam(lr = 0.01),
  loss = negloglik
)

model %&gt;% fit(x, y, epochs = 1000)
```

---
# The network has learned about variance in the data


```r
yhat &lt;- model(tf$constant(x_test))
mean &lt;- yhat %&gt;% tfd_mean()
sd &lt;- yhat %&gt;% tfd_stddev()
```

&lt;figure&gt;
    &lt;img src="https://raw.githubusercontent.com/skeydan/whyR2019/master/aleatoric.png" width = "80%"&gt;
&lt;/figure&gt;


---
# How about epistemic uncertainty?

Use _tfprobability_ variational layers:


- layer_dense_variational

- layer_dense_flipout

- layer_dense_reparameterization

- layer_dense_local_reparameterization

- layer_conv_nd_flipout (n = [1..3])

- layer_conv_nd_flipout (n = [1..3])

- layer_conv_nd_flipout (n = [1..3])

---
# Posterior weights are computed using variational inference

&lt;figure&gt;
    &lt;img src="https://raw.githubusercontent.com/skeydan/whyR2019/master/blei_vi.png" width = "80%"&gt;
    &lt;figcaption&gt;Source: &lt;a href="https://media.nips.cc/Conferences/2016/Slides/6199-Slides.pdf"&gt;David Blei, Rajesh Ranganath, Shakir Mohamed: Variational Inference:Foundations and Modern Methods. NIPS 2016 Tutorial·December 5, 2016.&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

---
# Example: Epistemic uncertainty


```r
model &lt;- keras_model_sequential() %&gt;%
  layer_dense_variational(
    units = 1,
    make_posterior_fn = posterior_mean_field,
    make_prior_fn = prior_trainable,
    kl_weight = 1 / n
  ) %&gt;%
  layer_distribution_lambda(
    function(x) tfd_normal(loc = x, scale = 1)
    )

negloglik &lt;- function(y, model) - (model %&gt;% tfd_log_prob(y))

model %&gt;% compile(
  optimizer = optimizer_adam(lr = 0.1),
  loss = negloglik
)

model %&gt;% fit(x, y, epochs = 1000)
```

---
# Now every prediction uses different _weight samples_


```r
yhats &lt;- purrr::map(1:100, function(x) model(tf$constant(x_test)))
```

&lt;figure&gt;
    &lt;img src="https://raw.githubusercontent.com/skeydan/whyR2019/master/epistemic.png" width = "80%"&gt;
&lt;/figure&gt;



---
# Aleatoric, epistemic ... why not have both? 


```r
model &lt;- keras_model_sequential() %&gt;%
  layer_dense_variational(
    units = 2,
  ) %&gt;%
  layer_distribution_lambda(function(x)
    tfd_normal(loc = x[, 1, drop = FALSE],
               scale = 1e-3 + tf$math$softplus(0.01 * x[, 2, drop = FALSE])
               )
    )

yhats &lt;- purrr::map(1:100, function(x) model(tf$constant(x_test)))
means &lt;-
  purrr::map(yhats, purrr::compose(as.matrix, tfd_mean)) %&gt;% abind::abind()
sds &lt;-
  purrr::map(yhats, purrr::compose(as.matrix, tfd_stddev)) %&gt;% abind::abind()
```


---
# Main challenge now is how to display ...

Each line is one draw from the posterior weights; each line has its own standard deviation.

&lt;figure&gt;
    &lt;img src="https://raw.githubusercontent.com/skeydan/whyR2019/master/both.png" width = "70%"&gt;
&lt;/figure&gt;

More background: https://blogs.rstudio.com/tensorflow/posts/2019-06-05-uncertainty-estimates-tfprobability/

---
class: inverse, middle, center

# Case study: Smartphone activity detection

---
# Non-probabilistic cassification

Nick Strayer, Classifying physical activity from smartphone data [https://blogs.rstudio.com/tensorflow/posts/2018-07-17-activity-detection/](https://blogs.rstudio.com/tensorflow/posts/2018-07-17-activity-detection/) 

&lt;br &gt;

&lt;figure&gt;
    &lt;img src="measurements.png" width = "110%"&gt;
&lt;/figure&gt;

---
# Original confusion matrix

&lt;figure&gt;
    &lt;img src="confusion_matrix.png" width = "80%"&gt;
&lt;/figure&gt;


---
# Goal: Port model to TensorFlow Probability

&lt;br /&gt;

- replace normal conv layers by _layer_conv_1d_flipout_

- replace deterministic output layer by _layer_one_hot_categorical_

- training objective: ELBO: minimize:
  
   - KL divergence between a (standard) multivariate normal prior and the approximate posterior
   - negative log probability of the data under the approximate posterior


---
# Probabilistic model


```r
model &lt;- keras_model_sequential()

model %&gt;% 
  layer_conv_1d_flipout(
    filters = 12,
    kernel_size = 3, 
    activation = "relu",
    kernel_divergence_fn = kl_div
  ) %&gt;%
  #...
  #...
  layer_dense_flipout(
    num_classes, 
    kernel_divergence_fn = kl_div,
  ) %&gt;%
  layer_one_hot_categorical(event_size = num_classes)

nll &lt;- function(y, model) - (model %&gt;% tfd_log_prob(y))
```

---
# Loss curve

&lt;figure&gt;
    &lt;img src="losscurve.png" width = "110%"&gt;
&lt;/figure&gt;


---
# Uncertainties

- __maxprob__: single-run highest per-obs mean of categorical distribution
- __maxprob_sd__: standard deviation associated with single-run highest per-obs mean of categorical distribution
- __maxprob_sd_mc__: standard deviation of means obtained from 100 prediction runs (weights are probabilistic!)

```
     obs maxprob maxprob_sd maxprob_mc_sd     predicted         truth correct
     
 1     1   0.997     0.0561        0.175    STAND_TO_SIT   STAND_TO_S…   TRUE   
 2     2   0.653     0.476         0.235    STAND_TO_SIT   STAND_TO_S…   TRUE   
 3     3   0.987     0.112         0.121    STAND_TO_SIT   STAND_TO_S…   TRUE   
 4     4   0.960     0.195         0.130    STAND_TO_SIT   STAND_TO_S…   TRUE   
 5     5   0.987     0.115         0.325    STAND_TO_SIT   STAND_TO_S…   TRUE   
 6     6   0.568     0.495         0.265    STAND_TO_SIT   STAND_TO_S…   TRUE   
 7     7   0.701     0.458         0.320    STAND_TO_SIT   STAND_TO_S…   TRUE   
 8     8   0.982     0.134         0.0651   STAND_TO_SIT   STAND_TO_S…   TRUE   
 9     9   0.589     0.492         0.235    STAND_TO_SIT   STAND_TO_S…   TRUE   
10    10   0.546     0.498         0.114    STAND_TO_SIT   STAND_TO_S…   TRUE   
11    11   0.798     0.401         0.220    STAND_TO_SIT   STAND_TO_S…   TRUE   
... 
```

---
# Are wrong classifications associated with higher uncertainty?

```
correct count   avg_mean   avg_sd   avg_mc_sd

FALSE      17      0.673    0.420       0.229
TRUE       52      0.814    0.314       0.178
```

```
truth          predicted    avg_mean   avg_sd avg_mc_sd   correct

SIT_TO_LIE     SIT_TO_LIE      0.904    0.240     0.136   TRUE   
LIE_TO_SIT     LIE_TO_STAND    0.532    0.498     0.153   FALSE  
SIT_TO_STAND   SIT_TO_STAND    0.904    0.238     0.165   TRUE   
STAND_TO_LIE   STAND_TO_LIE    0.833    0.297     0.179   TRUE   
LIE_TO_STAND   LIE_TO_STAND    0.651    0.470     0.191   TRUE   
STAND_TO_SIT   STAND_TO_SIT    0.814    0.290     0.194   TRUE   
LIE_TO_SIT     LIE_TO_SIT      0.682    0.448     0.196   TRUE   
LIE_TO_STAND   LIE_TO_SIT      0.639    0.454     0.213   FALSE  
SIT_TO_LIE     STAND_TO_SIT    0.692    0.462     0.240   FALSE  
SIT_TO_LIE     STAND_TO_LIE    0.738    0.379     0.265   FALSE  
STAND_TO_LIE   SIT_TO_LIE      0.813    0.282     0.299   FALSE
```

---
# Where to from here?

&lt;br /&gt;

- TensorFlow Probability is under rapid development

- Follow the TensorFlow for R blog for updates: https://blogs.rstudio.com/tensorflow/

&lt;br /&gt;

## Thanks for your attention!
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
